1) Immediate containment (do these now)

Kill write access to prod

In Neon → Rotate the password for the current prod user (the one in DATABASE_URL).

Create a temporary read-only user and set it as DATABASE_URL while we restore (steps below).

-- Run in Neon SQL console on the prod DB
CREATE ROLE app_readonly LOGIN PASSWORD 'TEMP_STRONG_PASSWORD';
GRANT CONNECT ON DATABASE neon TO app_readonly;
GRANT USAGE ON SCHEMA public TO app_readonly;
GRANT SELECT ON ALL TABLES IN SCHEMA public TO app_readonly;
ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT ON TABLES TO app_readonly;

Update Replit Secrets: DATABASE_URL → use the readonly user you just made. Restart the app.


Disable destructive Prisma in prod

In Replit, delete/disable any scripts that run prisma db push or anything with --force-reset.

Until hardening is in place (section 3), nobody runs Prisma migrations against prod.




---

2) Restore data (Neon point-in-time fast path)

> Assumption: you’re on Neon (Model Context confirms Neon Postgres). Times below are Asia/Bangkok (UTC+7).



1. Pick restore point
From your timeline above, the destructive command happened roughly ~4–30 minutes before your message. Choose a conservative timestamp from before the reset, e.g.
2025-11-01 09:00:00 +07:00 (adjust if you know a more exact “pre-reset” minute).


2. Create a branch from that time

Neon Console → Branches → New branch → “Create from point-in-time”

Select prod DB → Timestamp: e.g., 2025-11-01 09:00:00+07

Name it: pre-reset-2025-11-01-0900-bkk



3. Verify the branch has your data

Open the branch SQL editor and run quick checks:

-- sanity checks: replace table names with yours if needed
SELECT COUNT(*) FROM daily_sales;
SELECT COUNT(*) FROM daily_stock;
SELECT COUNT(*) FROM pos_receipts;
SELECT COUNT(*) FROM ingredients;
SELECT COUNT(*) FROM recipes;
SELECT MIN(created_at), MAX(created_at) FROM daily_sales;

You should not see zeros across the board. Spot-check a few rows.



4. Promote or re-point prod

Option A (swap connection): Update Replit’s DATABASE_URL to point to the restored branch (fastest).

Option B (promote): In Neon, merge/promote the restored branch as the main prod branch, then point DATABASE_URL back to prod.



5. Bring app back read/write (carefully)

Create the hardened roles from section 3 (app_user/migrator_user) and update DATABASE_URL to the app_user only after hardening is complete.





---

3) Hardening (Fort-Knox, prevents a repeat)

3.1 Postgres roles: least privilege (run on the restored prod DB)

> Replace neon with your DB name if different; change passwords.



-- 1) Owner role (no login; owns objects; app/migrator do not)
CREATE ROLE db_owner NOLOGIN;

-- 2) Runtime app role (NO DDL)
CREATE ROLE app_user LOGIN PASSWORD 'APP_STRONG_PASSWORD';
GRANT CONNECT ON DATABASE neon TO app_user;
GRANT USAGE ON SCHEMA public TO app_user;
REVOKE CREATE ON SCHEMA public FROM PUBLIC;

GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO app_user;
GRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA public TO app_user;
ALTER DEFAULT PRIVILEGES IN SCHEMA public
  GRANT SELECT, INSERT, UPDATE, DELETE ON TABLES TO app_user;
ALTER DEFAULT PRIVILEGES IN SCHEMA public
  GRANT USAGE, SELECT ON SEQUENCES TO app_user;

-- 3) Migrator role (used ONLY for `prisma migrate deploy`)
CREATE ROLE migrator_user LOGIN PASSWORD 'MIGRATOR_STRONG_PASSWORD';
GRANT CONNECT ON DATABASE neon TO migrator_user;
GRANT USAGE, CREATE ON SCHEMA public TO migrator_user;

-- Ensure new objects are owned by db_owner (not migrator) post-migration:
-- After each migration deploy, transfer ownership:
--   DO $$ DECLARE r record;
--   BEGIN
--     FOR r IN SELECT 'public.'||c.relname AS full FROM pg_class c JOIN pg_namespace n ON n.oid=c.relnamespace WHERE n.nspname='public' AND c.relkind IN ('r','S','v','m')
--     LOOP EXECUTE 'ALTER ' || (CASE WHEN r.full LIKE '%.%' THEN 'TABLE ' ELSE '' END) || r.full || ' OWNER TO db_owner'; END LOOP;
--   END $$;

-- 4) Lock down PUBLIC and miscellaneous
REVOKE ALL ON DATABASE neon FROM PUBLIC;
REVOKE USAGE ON SCHEMA public FROM PUBLIC;

Production app uses app_user only.

Migrations use migrator_user with prisma migrate deploy (never db push in prod).

After migrations, transfer ownership to db_owner so the migrator cannot drop objects by ownership.


3.2 Safe NPM scripts (block destructive commands)

package.json (prod-safe scripts only)

{
  "scripts": {
    "dev": "vite",
    "build": "vite build && ts-node scripts/assert-routes-registered.mjs",
    "start": "node server/index.js",
    "migrate:dev": "node scripts/prisma-guard.mjs ensure-dev && prisma migrate dev",
    "migrate:deploy": "node scripts/prisma-guard.mjs ensure-prod && prisma migrate deploy",
    "prisma:generate": "prisma generate",
    "prisma:status": "prisma migrate status",
    "backup:db": "node scripts/backup_db.mjs",
    "smoke": "node scripts/smoke_test.mjs"
  }
}

scripts/prisma-guard.mjs

#!/usr/bin/env node
import crypto from "crypto";

const mode = process.argv[2]; // ensure-dev | ensure-prod
const env = process.env.NODE_ENV || "development";
const url = process.env.DATABASE_URL || "";

function die(msg) { console.error(msg); process.exit(1); }

if (mode === "ensure-dev") {
  if (env !== "development") die("Blocked: migrate dev outside development.");
  process.exit(0);
}

if (mode === "ensure-prod") {
  if (env !== "production") die("Blocked: migrate deploy requires NODE_ENV=production.");
  if (!/postgresql:\/\/.+@.+neon\.tech\/.+/i.test(url)) {
    die("Blocked: production deploy must target Neon prod URL.");
  }
  const forbidden = ["db", "push", "reset", "--force-reset"];
  if (forbidden.some(f => process.env.npm_lifecycle_script?.includes(f))) {
    die("Blocked: destructive Prisma command in production.");
  }
  process.exit(0);
}

die("Usage: prisma-guard.mjs ensure-dev|ensure-prod");

> Delete any old reset, db push, or seed scripts that target prod. Keep them dev only with .env.development.



3.3 Route-registration tripwire (prevents the original “404/Failed to fetch”)

scripts/assert-routes-registered.mjs

#!/usr/bin/env node
import fs from "fs";

const serverIndex = "server/index.ts"; // adjust if needed
const mustInclude = [
  "analysisDailyReview",        // import line must exist
  "app.use('/api/analysis',"    // mounted router
];

const src = fs.readFileSync(serverIndex, "utf8");
for (const token of mustInclude) {
  if (!src.includes(token)) {
    console.error(`[ROUTE CHECK] Missing token: ${token} in ${serverIndex}`);
    process.exit(1);
  }
}
console.log("[ROUTE CHECK] OK");

> This runs during build to fail fast if /api/analysis/* routes aren’t registered again.



3.4 Automated backups (hourly snapshot)

scripts/backup_db.mjs

#!/usr/bin/env node
import { execSync } from "child_process";
import fs from "fs";

const url = process.env.DATABASE_URL;
if (!url) { console.error("DATABASE_URL missing"); process.exit(1); }

const ts = new Date().toISOString().replace(/[:.]/g, "-");
const outDir = "./backups";
const outFile = `${outDir}/backup_${ts}.sqlc`;

fs.mkdirSync(outDir, { recursive: true });
try {
  execSync(`pg_dump "${url}" -Fc -f "${outFile}"`, { stdio: "inherit" });
  console.log(`Backup written: ${outFile}`);
} catch (e) {
  console.error("pg_dump failed. Ensure pg_dump is available in Replit or run this from your CI.");
  process.exit(1);
}

Schedule via Replit “Always On” + a small cron-like node loop or your CI to run npm run backup:db every hour.

Keep last N snapshots; mirror to Drive/S3 if you want redundancy.


3.5 Smoke test (verifies critical paths)

scripts/smoke_test.mjs

#!/usr/bin/env node
import http from "http";

const tests = [
  { name: "Daily comparison", path: "/api/analysis/daily-comparison?date=2025-10-31" },
  { name: "Daily comparison range", path: "/api/analysis/daily-comparison-range?month=2025-10" }
];

function get(path) {
  return new Promise((resolve, reject) => {
    const req = http.request({ host: "localhost", port: 5000, path, method: "GET" }, res => {
      let data=""; res.on("data", c => data+=c); res.on("end", () => resolve({status: res.statusCode, data}));
    });
    req.on("error", reject); req.end();
  });
}

(async () => {
  let failed = false;
  for (const t of tests) {
    try {
      const r = await get(t.path);
      if (r.status !== 200) { console.error(`[SMOKE] ${t.name} -> ${r.status}`); failed = true; }
      else { console.log(`[SMOKE] ${t.name} OK`); }
    } catch (e) { console.error(`[SMOKE] ${t.name} ERROR`, e.message); failed = true; }
  }
  process.exit(failed ? 1 : 0);
})();

> Add this to your deploy pipeline so a bad route or server regression blocks deployment.




---

4) One-page operator checklist (what to run/click)

1. Neon Console → rotate prod user password and set temporary readonly DB user in DATABASE_URL. Restart app.


2. Create PITR branch at a time just before the reset (2025-11-01 09:00 +07:00 as a safe example).


3. Verify counts on daily_sales, daily_stock, pos_receipts, ingredients, recipes.


4. Point DATABASE_URL to the restored branch and restart. Confirm UI and APIs show historical data again.


5. Run hardening SQL (roles section). Create app_user and migrator_user. Update DATABASE_URL to app_user.


6. Update repo:

Replace package.json scripts.

Add scripts/prisma-guard.mjs, scripts/assert-routes-registered.mjs, scripts/backup_db.mjs, scripts/smoke_test.mjs.

Remove any script that runs prisma db push in prod.



7. Deploy. On deploy, npm run build should pass the route check; npm run smoke should pass locally.


8. Schedule backups (npm run backup:db hourly) and keep the last 72 files.




---

5) Regarding “expenses missing” / 404s

The earlier outage (“Failed to fetch”) matches an unregistered router. The tripwire in §3.3 prevents that class of mistake.

If expenses still read “missing” after restore, run the smoke test and confirm the API payload includes pos.expenses and form.expenses. If not, the comparison query or JSON mapping needs a quick fix; but first restore and lock down.



---
